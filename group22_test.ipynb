{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display,HTML\n",
    "import joblib\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 0.5*height,'%d' % int(height),ha='center', va='bottom',color='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data (filename=group22_test.dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.genfromtxt('group22_test.dat',delimiter=\",\", dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set m and n\n",
    "m_test = test_data.shape[0]\n",
    "n_test = test_data.shape[1]-1\n",
    "\n",
    "#Set X and y\n",
    "X_test = test_data[:,0:n_test]\n",
    "y_test = test_data[:,n_test].reshape(m_test,1)\n",
    "\n",
    "#Scale data\n",
    "X_test = X_test / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    used for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_recons = X_test.reshape(m_test,64,64,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trained logistic regression model\n",
    "joblib_model = joblib.load('logreg.pkl')\n",
    "\n",
    "#predict image class using trained model\n",
    "ypred = joblib_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Display confusion matrics\n",
    "print(\"******************************\\n\")\n",
    "\n",
    "#Overall Accuracy\n",
    "print (\"Logistic Regression Overall accuracy : \"+str(accuracy_score( y_test, ypred )*100 ))\n",
    "\n",
    "#Confusion matrix\n",
    "conmatrix = confusion_matrix(y_test, ypred)\n",
    "\n",
    "#Precision score\n",
    "print(\"Logistic Regression Precision :\"+str(precision_score(y_test, ypred,average='weighted')*100))\n",
    "\n",
    "#F1 score\n",
    "print(\"Logistic Regression F1 score :\" +str( f1_score(y_test, ypred,average='weighted')*100) )\n",
    "\n",
    "### Per-Class accuracy\n",
    "logregclasses = np.diagonal(conmatrix)\n",
    "\n",
    "print(\"\\n******************************\\n\")\n",
    "print(\"Logistic Regression Per class Accuracy Score\\n\")\n",
    "for i in range(len(logregclasses)):\n",
    "    if i == 0:\n",
    "        print(\"Class 0 | Accuracy score = \" +str(logregclasses[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 1:\n",
    "        print(\"Class 1 | Accuracy score = \" +str(logregclasses[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 2:\n",
    "        print(\"Class 2 | Accuracy score = \" +str(logregclasses[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 3:\n",
    "        print(\"Class 3 | Accuracy score = \" +str(logregclasses[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 4:\n",
    "        print(\"Class 4 | Accuracy score = \" +str(logregclasses[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 5:\n",
    "        print(\"Class 5 |  Accuracy score = \" +str(logregclasses[i]*2))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "\n",
    "plt.imshow(conmatrix, cmap=plt.cm.Wistia)\n",
    "\n",
    "plt.ylabel('TRUE LABEL')\n",
    "plt.xlabel('PREDICTED LABEL')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "          plt.text(i,j, str(conmatrix[i][j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Additional relevent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall score\n",
    "print(\"******************************\")\n",
    "print(\" Logistic Regression Recall : \"+str( recall_score(y_test, ypred,average='weighted')*100) )\n",
    "print(\"******************************\\n\")\n",
    "print(\"******************************\\n\")\n",
    "\n",
    "print('Logistic Regression Report\\n')\n",
    "print(classification_report(y_test, ypred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Bar graph (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.diagonal(conmatrix)\n",
    "incorrect = np.sum(conmatrix,axis=1)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "correct.setflags(write=1)\n",
    "for i in range( len(correct)):\n",
    "    incorrect[i] = (incorrect[i] - correct[i])*2\n",
    "    correct[i] = correct[i]*2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(6)\n",
    "bar_width = 0.35\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "\n",
    "rects1 = ax.bar(index, correct, bar_width,alpha=opacity, color='b',error_kw=error_config,label='correct')\n",
    "rects2 = ax.bar(index+bar_width, incorrect, bar_width,alpha=opacity, color='r',error_kw=error_config,label='incorrect')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Correct/Incorrect (%)')\n",
    "ax.set_title('Logistic Regression Histogram ')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(('0','1', '2', '3', '4', '5'))\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    display 10 images (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (50, 50)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(20,1,i+1)\n",
    "    plt.imshow(X_test_recons[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"A :\"+str(np.ravel(y_test)[i]) + \" P :\"+str(np.ravel(ypred)[i] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trained NN classifier\n",
    "joblib_model = joblib.load('NN.pkl')\n",
    "\n",
    "#predict image class using NN trained classifier\n",
    "yn_pred = joblib_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall Accuracy\n",
    "print (\"NN Overall accuracy : \"+str(accuracy_score( y_test, yn_pred )*100 ))\n",
    "\n",
    "#Confusion matrix\n",
    "con_nn_matrix = confusion_matrix(y_test, yn_pred)\n",
    "\n",
    "\n",
    "#Precision score\n",
    "print(\"NN Precision :\"+str(precision_score(y_test, yn_pred,average='weighted')*100))\n",
    "\n",
    "print(\"NN F1 score :\" +str( f1_score(y_test, yn_pred,average='weighted')*100) )\n",
    "\n",
    "### Per-Class accuracy\n",
    "classes = np.diagonal(con_nn_matrix)\n",
    "\n",
    "print(\"\\n******************************\\n\")\n",
    "print(\"NN PER CLASS ACCURACY SCORE\\n\")\n",
    "for i in range(len(classes)):\n",
    "    if i == 0:\n",
    "        print(\"Class 0 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 1:\n",
    "        print(\"Class 1 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 2:\n",
    "        print(\"Class 2 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 3:\n",
    "        print(\"Class 3 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 4:\n",
    "        print(\"Class 4 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 5:\n",
    "        print(\"Class 5 | Accuracy score = \" +str(classes[i]*2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Confusion Matric (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "plt.imshow(con_nn_matrix, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "\n",
    "plt.ylabel('TRUE LABEL')\n",
    "plt.xlabel('PREDICTED LABEL')\n",
    "plt.title('NN CONFUSION MATRIX')\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "          plt.text(j,i, str(con_nn_matrix[i][j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Bar Graph ( Neural Network )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.diagonal(con_nn_matrix)\n",
    "incorrect = np.sum(con_nn_matrix,axis=0)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "correct.setflags(write=1)\n",
    "for i in range( len(correct)):\n",
    "    incorrect[i] = (incorrect[i] - correct[i])*2\n",
    "for i in range( len(correct)):\n",
    "    correct[i] = (correct[i])*2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(6)\n",
    "bar_width = 0.35\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "\n",
    "rects1 = ax.bar(index, correct, bar_width,alpha=opacity, color='b',error_kw=error_config,label='correct')\n",
    "rects2 = ax.bar(index+ bar_width, incorrect, bar_width,alpha=opacity, color='r',error_kw=error_config,label='incorrect')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Correct/Incorrect')\n",
    "ax.set_title('NN Accuracy')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(('0','1', '2', '3', '4', '5'))\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (50, 50)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(20,1,i+1)\n",
    "    plt.imshow(X_test_recons[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"A :\"+str(np.ravel(y_test)[i]) + \" P :\"+str(np.ravel(yn_pred)[i] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trained SVM Model\n",
    "joblib_model = joblib.load('SVM.pkl')\n",
    "\n",
    "#Predict images using trained SVM Model\n",
    "ysvm_pred = joblib_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall Accuracy\n",
    "print (\"SVM Overall accuracy : \"+str(accuracy_score( y_test, ysvm_pred )*100 ))\n",
    "\n",
    "#Confusion matrix\n",
    "con_matrix = confusion_matrix(y_test, ysvm_pred)\n",
    "\n",
    "#Precision score\n",
    "print(\"SVM Precision :\"+str(precision_score(y_test, ysvm_pred,average='weighted')*100))\n",
    "\n",
    "print(\"SVM F1 score :\" +str( f1_score(y_test, ysvm_pred,average='weighted')*100) )\n",
    "\n",
    "### Per-Class accuracy\n",
    "classes = np.diagonal(con_matrix)\n",
    "\n",
    "print(\"\\n******************************\\n\")\n",
    "print(\"SVM PER CLASS ACCURACY SCORE\\n\")\n",
    "for i in range(len(classes)):\n",
    "    if i == 0:\n",
    "        print(\"Class 0 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 1:\n",
    "        print(\"Class 1 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 2:\n",
    "        print(\"Class 2 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 3:\n",
    "        print(\"Class 3 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 4:\n",
    "        print(\"Class 4 | Accuracy score = \" +str(classes[i]*2))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if i == 5:\n",
    "        print(\"Class 5 | Accuracy score = \" +str(classes[i]*2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "plt.imshow(con_matrix, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "\n",
    "plt.ylabel('TRUE LABEL')\n",
    "plt.xlabel('PREDICTED LABEL')\n",
    "plt.title('SVM CONFUSION MATRIX')\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "          plt.text(j,i, str(con_matrix[i][j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITIONAL RESOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Bar Braph (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.diagonal(con_matrix)\n",
    "incorrect = np.sum(con_matrix,axis=0)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "correct.setflags(write=1)\n",
    "for i in range( len(correct)):\n",
    "    incorrect[i] = (incorrect[i] - correct[i])*2\n",
    "for i in range( len(correct)):\n",
    "    correct[i] = (correct[i])*2\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(6)\n",
    "bar_width = 0.35\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "\n",
    "rects1 = ax.bar(index, correct, bar_width,alpha=opacity, color='b',error_kw=error_config,label='correct')\n",
    "rects2 = ax.bar(index+ bar_width, incorrect, bar_width,alpha=opacity, color='r',error_kw=error_config,label='incorrect')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Correct/Incorrect')\n",
    "ax.set_title('SVM Accuracy')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(('0','1', '2', '3', '4', '5'))\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    display few images (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (50, 50)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(20,1,i+1)\n",
    "    plt.imshow(X_test_recons[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"A :\"+str(np.ravel(y_test)[i]) + \" P :\"+str(np.ravel(ysvm_pred)[i] )    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall score\n",
    "print(\"******************************\")\n",
    "print(\" SVM Recall : \"+str( recall_score(y_test, ysvm_pred,average='weighted')*100) )\n",
    "print(\"******************************\\n\")\n",
    "\n",
    "\n",
    "print('SVM Report\\n')\n",
    "print(classification_report(y_test, ysvm_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 6\n",
    "\n",
    "svmacc = np.diagonal(con_matrix)\n",
    "logrecacc= np.diagonal(conmatrix)\n",
    "nn_classes = np.diagonal(con_nn_matrix)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.20\n",
    "\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = ax.bar(index, svmacc, bar_width,alpha=opacity, color='b', error_kw=error_config,label='SVM')\n",
    "rects2 = ax.bar(index + bar_width, logrecacc, bar_width,alpha=opacity, color='r', error_kw=error_config,label='Logistic Regression')\n",
    "rects3 = ax.bar(index + bar_width*2, nn_classes, bar_width,alpha=opacity, color='y', error_kw=error_config,label='Neural Network')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('Per Class Accuracy')\n",
    "ax.set_title('Per Class Accuracy for the Three techniques')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(('0','1', '2', '3', '4', '5'))\n",
    "plt.rc('xtick', labelsize=20) \n",
    "plt.rc('ytick', labelsize=20)\n",
    "ax.legend(loc='lower left')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
